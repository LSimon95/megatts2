# lightning.pytorch==2.1.0
seed_everything: true
trainer:
  logger:
    class_path: lightning.pytorch.loggers.tensorboard.TensorBoardLogger
    init_args:
      save_dir: logs/
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelSummary
      init_args:
        max_depth: 3
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: val/loss_re
        filename: nikatts_ar_checkpoint_{epoch}_{step}_{val/loss_re:.4f}
        save_top_k: 5
        save_last: true
        every_n_epochs: 1
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
  # ~ 3 epochs
  max_steps: 600000
  # # You might want to limit val batches when evaluating all the metrics, as they are time-consuming
  # limit_val_batches: 100
  accelerator: gpu
  log_every_n_steps: 100
  val_check_interval: 3000
  check_val_every_n_epoch: 1

  # strategy: ddp
  # devices: [0, 1]
  # use_distributed_sampler: false

  devices: [0]
model:
  G: 
    class_path: models.megatts2.MegaVQ
    init_args:
      mrte:
        class_path: modules.mrte.MRTE
        init_args:
          mel_bins: 80
          mel_frames: 256
          attn_dim: 512
          ff_dim: 1024
          n_heads: 2
          n_layers: 8
          ge_kernel_size: 31
          ge_hidden_sizes:
          - 80
          - 256
          - 256
          - 512
          - 512
          ge_activation: ReLU
          ge_out_channels: 512
          duration_tokne_ms: 16.0
          phone_vocab_size: 320
          dropout: 0.1
          sample_rate: 16000
      vqpe:
        class_path: modules.vqpe.VQProsodyEncoder
        init_args:
          hidden_sizes:
          - 80
          - 256
          - 256
          - 512
          - 512
          kernel_size: 5
          stack_size: 3
          activation: ReLU
      decoder:
        class_path: modules.convnet.ConvNet
        init_args:
          hidden_sizes:
          - 1024
          - 512
          - 256
          - 256
          - 80
          kernel_size: 5
          stack_size: 3
          activation: ReLU
          avg_pooling: false
  D:
    class_path: modules.dscrm.Discriminator
    init_args:
      time_lengths:
      - 24
      - 48
      - 96
      freq_length: 80
      kernel:
      - 3
      - 3
      c_in: 1
      hidden_size: 128
  initial_learning_rate: 2e-5
  warmup_steps: 200.0

  G_commit_loss_coeff: 0.1
  G_vq_loss_coeff: 0.05
  G_adv_loss_coeff: 1.0
  train_dtype: bfloat16
  class_path: models.trainer.MegaGANTrainer
data:
  ds_path: /root/autodl-tmp/megatts2/data/ds/
  max_duration_batch: 22
  min_duration: 1.6
  max_duration: 20
  num_buckets: 10
  num_workers: 4
  class_path: modules.datamodule.TTSDataModule
ckpt_path: last.ckpt