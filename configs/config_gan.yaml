# lightning.pytorch==2.1.0
seed_everything: true
trainer:
  logger:
    class_path: lightning.pytorch.loggers.tensorboard.TensorBoardLogger
    init_args:
      save_dir: logs/
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelSummary
      init_args:
        max_depth: 3
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: val/loss_re
        filename: nikatts_ar_checkpoint_{epoch}_{step}_{val/loss_re:.4f}
        save_top_k: 5
        save_last: true
        every_n_epochs: 1
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
  # ~ 3 epochs
  max_steps: 600000
  # # You might want to limit val batches when evaluating all the metrics, as they are time-consuming
  # limit_val_batches: 100
  accelerator: gpu
  log_every_n_steps: 100
  val_check_interval: 1500
  check_val_every_n_epoch: 1

  # strategy: ddp
  # devices: [0, 1]
  # use_distributed_sampler: false

  devices: [0]
model:
  G:
    class_path: models.megatts2.MegaG
    init_args:
      mrte:
        class_path: modules.mrte.MRTE
        init_args:
          mel_bins: 80
          mel_frames: 256
          mel_activation: ReLU
          mel_kernel_size: 3
          mel_stride: 16
          mel_n_layer: 5
          mel_n_stack: 5
          mel_n_block: 2
          content_ff_dim: 1024
          content_n_heads: 2
          content_n_layers: 8
          hidden_size: 512
          duration_token_ms: 16.0
          phone_vocab_size: 320
          dropout: 0.1
          sample_rate: 16000
      vqpe:
        class_path: modules.vqpe.VQProsodyEncoder
        init_args:
          mel_bins: 20
          stride: 8
          hidden_size: 384
          kernel_size: 5
          n_layers: 3
          n_stacks: 5
          n_blocks: 2
          vq_bins: 1024
          vq_dim: 256
          activation: ReLU
      kernel_size: 5
      activation: ReLU
      hidden_size: 512
      decoder_n_stack: 4
      decoder_n_block: 2
  D:
    class_path: modules.dscrm.Discriminator
    init_args:
      time_lengths:
      - 32
      - 64
      - 128
      freq_length: 80
      kernel:
      - 3
      - 3
      c_in: 1
      hidden_size: 192
  initial_learning_rate: 3e-5
  warmup_steps: 200.0

  G_commit_loss_coeff: 0.15
  G_vq_loss_coeff: 0.05
  G_adv_loss_coeff: 1.0
  train_dtype: bfloat16
  class_path: models.trainer.MegaGANTrainer
data:
  ds_path: /root/autodl-tmp/megatts2/data/ds/
  max_duration_batch: 60
  min_duration: 2.1
  max_duration: 20
  num_buckets: 10
  num_workers: 4
  class_path: modules.datamodule.TTSDataModule
ckpt_path: null